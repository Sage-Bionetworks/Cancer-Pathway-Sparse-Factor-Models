# e2f3QC.R

# Erich S. Huang
# Sage Bionetworks
# Seattle, Washington
# erich.huang@sagebase.org

##########
# LOAD IN REQUIRED LIBRARIES
##########

require(mGenomics)
require(snm)
require(ggplot2)
require(Biobase)
require(synapseClient)
mplotEnt <- loadEntity('syn274067')
attach(mplotEnt)

# synapseLogin('username', 'password')

##########
# LOAD IN RAW DATA ENTITY FROM SCR
##########

e2f3Ent <- loadEntity('syn138509')
fits <- runWorkflow(e2f3Ent$cacheDir, workflow = 'snm')

##########
# PULL OUT THE EXPRESSION DATA
##########

exprDat <- exprs(fits$hgu133plus2[[1]])

# Create a treatment model matrix  (using the filename annotations)
treatment <- ifelse(grepl('E2F3', list.files(e2f3Ent$cacheDir)), "GFP", "E2F3")
X <- model.matrix(~ factor(treatment))
sigObj <- calcSig(exprDat, X)

##########
# GENERATE FIGURES ON DATA PRIOR TO SUPERVISED NORMALIZATION
##########

varBarPlot <- pvalHistFig1(sigObj)

svdObj <- fs(exprDat)

initPcPlots <- pcPlotsFig2(svdObj)

##########
# REGRESS OUT THE KNOWN EXPERIMENTAL PERTURBATION EFFECT (TREATMENT)
##########

# In order to better understand perturbation-independent latent structure in
# the data

# Calculate the total sums of squares of the data.
datM <- rowMeans(exprDat)
datC <- sweep(exprDat, 1, datM)
tSSQ_dat <- sum(datC^2)

# Now we want to remove the effects of the biological treatment
# on the data.  The reason is we are interested in identifying 
# any latent structure. In order to do so we calculate the
# residual sums of squares and take a singular value decomposition
# of the data.  Note the singular values are weighted to sum to 1.
residuals <- exprDat - t(X %*% solve(t(X) %*% X) %*% t(X) %*% t(exprDat))
rSSQ_dat <- sum(residuals^2)
u <- fs(residuals)
propSSQ <- round(rSSQ_dat * u$d, 3) / tSSQ_dat

# Generate a figure
propSSQBarPlot <- propSSQFig3(propSSQ)

# Visual inspection of this figure suggests that the dependence kernel 
# should be set as rank 2
svaFit <- sva(exprDat, bio.var = X, n.sv = 2, num.iter = 30, diagnose = FALSE)

# Now, we'll take a look at the estimated basis vectors 
svaDF <- as.data.frame(cbind(1:19, svaFit$svd[[30]]$v))
colnames(svaDF) <- c('sample', paste('adjPrinComp', 1:2, sep = ''))

adjSVDFig1 <- ggplot(svaDF, aes(sample, adjPrinComp1)) +
  geom_point(aes(colour = factor(treatment))) +
  opts(title = 'Treatment "Depleted" E2F3 Eigengene 1 Loadings\n') +
  xlab('\nSample') +
  ylab('Eigengene 1 Loading\n')

adjSVDFig2 <- ggplot(svaDF, aes(sample, adjPrinComp2)) +
  geom_point(aes(colour = factor(treatment))) +
  opts(title = 'Treatment "Depleted" E2F3 Eigengene 2 Loadings\n') +
  xlab('\nSample') +
  ylab('Eigengene 2 Loading\n')

adjCompositeFig <- multiplot(adjSVDFig1,
                             adjSVDFig2,
                             cols = 2)


# The plots suggest that even with the experimental perturbation effect
# removed there is still latent structure that correlates with the 
# experimental treatment.

# One way to manages this is to estimate a dependence kernel from transcripts
# that are non-varying, as determined using the pi0 statistic to define a 
# significance cutoff. Basically, a dependence kernel is generated by taking
# an unweighted SVD of the data restricted to the first pi0 largest ranked 
# (by p values) transcripts.

# Get the null probes
nullProbes <- which(rank(1 - sigObj$pval) < (length(sigObj$pval) * sigObj$pi0))
u <- fs(exprDat[nullProbes,])
Z <- model.matrix(~ u$v[,1:4])

# Use the null probes to build a dependence kernel and renormalize the data
fits2 <- runWorkflow(e2f3Ent$cacheDir,
                     workflow = "snm", bio.var = X, adj.var = Z, rm.adj = TRUE) 

dat2 <- exprs(fits2$hgu133plus2[[1]])
u2 <- fs(dat2)

# Visualize the normalized data
normDF <- as.data.frame(cbind(1:19, u2$v))
colnames(normDF) <- c('samples', paste('normPrinComp', 1:19, sep = ''))

normFig1 <- ggplot(normDF, aes(samples, normPrinComp1)) +
  geom_point(aes(colour = factor(treatment))) +
  opts(title = 'Normalized Data: E2F3 Eigengene 1\n') +
  xlab('/nSamples') +
  ylab('Eigengene 1 Loading/n')

normFig2 <- ggplot(normDF, aes(samples, normPrinComp2)) +
  geom_point(aes(colour = factor(treatment))) +
  opts(title = 'Normalized Data: E2F3 Eigengene 2\n') +
  xlab('/nSamples') +
  ylab('Eigengene 2 Loading/n')

normFig3 <- ggplot(normDF, aes(samples, normPrinComp3)) +
  geom_point(aes(colour = factor(treatment))) +
  opts(title = 'Normalized Data: E2F3 Eigengene 3\n') +
  xlab('/nSamples') +
  ylab('Eigengene 3 Loading/n')

normFig4 <- ggplot(normDF, aes(samples, normPrinComp4)) +
  geom_point(aes(colour = factor(treatment))) +
  opts(title = 'Normalized Data: E2F3 Eigengene 4\n') +
  xlab('/nSamples') +
  ylab('Eigengene 4 Loading/n')

multiplot(normFig1, normFig2, normFig3, normFig4, cols = 2)

##########
# MAKE AN ESET OUT OF THE NORMALIZED DATA
##########

nE2F3Eset <- fits2$hgu133plus2$eset
tempPhen <- pData(nE2F3Eset)
tempPhen$treatment <- treatment
pData(nE2F3Eset) <- tempPhen

##########
# RUN BFRM IN THE SPARSE ANOVA MODE
##########

require(bfrm)

e2f3Anova <- bfrm(dat2, design = ifelse(treatment == 'E2F3', 1, 0))
mPPib <- e2f3Anova@results$mPostPib
topProbeLogical <- mPPib[ , 2] >= 0.99
topProbeInd <- grep("TRUE", topProbeLogical)

##########
# RUN BFRM IN THE FACTOR DISCOVERY MODE
##########

bCatEvolveFactor <- evolve(dat2, 
                           init = as.numeric(topProbeInd),
                           priorpsia = 2,
                           priorpsib = 0.005,
                           varThreshold = 0.85,
                           facThreshold = 0.95,
                           maxVarIter = 30,
                           minFacVars = 10,
                           maxFacVars = length(topProbeInd),
                           maxFacs = 50,
                           maxVars = length(topProbeInd)
                           )


##########
# SAVE ENTITIES
##########

# See syn346115 for result objects